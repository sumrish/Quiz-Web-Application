TEAM H - checkout 27795947673b4712600201c4922ddb978a8f1014

## Team submission

Total: (91/100)

_well laid out and explained_
_performance reviews should include more specifics about what each team member did and suggestions to improve their productivity_
_I was not able to register to take a quiz at your atlas/cloud server, so I could not verify some of the test modules were actually working. There seems to be some discrepancy between what you report working and what I could test working._
_Adithya seems to be using the concept of a user story incorrectly in the individual contributions document_
_The installer did not set up tests to run correctly, I am getting a missing library. Someone from the team will have to meet with me between Apr 17 and apr 20 to show me how to set up the tests or I will not be able to give you credit on implementation and unit testing for the final submission._

_Is code review beign done correctly? There are notes on code review in the individual submissions, but code review is a team task and requires adoption of a coding standard and refernce to coding principles. Was this done?_

_A comprehensive architecture documentation will be needed in the next submission_

Team submission evaluation will be based on the following:

* The README file in your repo will be read by the evaluator to run the program, unit tests, and find out what other documentation the evaluator should read.
  * The content of the Kanban Board, issue tracker, and repo will be reviewed, but you may need to identify particular uses (of KanBan cards, issue tracker or other documentation tools) in your process documents or README.
  * Other documents can/should be put in a documents folder in your repo
  * If you are using other github tools that need to be reviewed (e.g. discussion or wiki tools) make sure this is made clear to the evaluator in the repo README file.

* Evaluation components will include:
  * (10/10%) Are the SCRUM meetings documented and all decisions documented properly and reflected in the Kanban Board and the issue tracker? Are decisions recorded in manner that provides for validation and traceability?
  * (8/10%) Are progress (individual tasks), performance (how did the team members perform) and code reviews conducted and documented, including the following:
    * This should be the primary agenda of the end-of-sprint SCRUM meeting.
    * Each code task has been code reviewed explicitly _Some reviews are general, vague and not referring to specific code elements._
    * Each team member has been performance reviewed explicitly (identify them)
    * The review process (x2) is identified, and may include a checklist for guidance and normalizing the review activity.
    _I could not find such a list, although the kanban board says it was done. Where is it?_
    * The process should be clear and concise, allowing the opportunity for the individual to respond to specific problems. (a full page of criticism is too long.)
    * Issues that arise from code and/or performance review are noted in the board. _some are noted, but use seems to be by some team members and not others_
  * (45/50%) Are the appropriate process elements established, followed and documented
    * (5/5%) meetings conducted appropriate contributions, with roles, notes and all decisions documented
    * (5/5%) Scrummaster and notetaker roles properly conducted and circulated among team members _are they sufficiently circulated?_
    * (5/5%) Current architecture and technology base (languages, modules, packages, tools) for project design described (including diagrams where needed) _This needs consolidation in next submission._
    * (5/5%) pull request deadlines and process and other workflow elements (git workflow) described and enforced for all team members _Specific dates were not given. Did I moss them in the meetong notes?_
    * (0/5%) code review standards clear and identified (possibly using a checklist) encapsulating principles from lecture materials (DRY, SOLID, etc.) updated and enforced by review _I could not find this element, code reviews seemed to be ideosyncratic between members, no common process established._
    * (25/25%) documentation, Kanban Board and issue tracker
      * labels and organization of issues in the tracker and cards on the board should be clear to the evaluator.
      * Completeness - the progress of tasks and issue status are clear from the board.
      * Labels have been modified for the team process. Labels help distinguish types of issues and tasks.
      * The board is clearly being used to update status and labels of tasks, and new cards identifying issues that arise are posted. 
      * Kanban task documentation can be linked to other more detailed documentation via card comments and web/http links.
  * (10/10%) Are any problems with the team progress, dynamics and process identified and documented along with status of these issues being clearly indicated _I am not convinced the status is clearly reflected in the board_
  * (18/20%) Unit testing
    * unit testing has been incorporated into code review and completed successfully for all coding tasks. _The description of testing and unit tests is not consistent between individual submission reports, so I have difficulty tracing which tests are for which tasks in the unit tests._ 
